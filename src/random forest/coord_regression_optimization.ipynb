{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization\n",
    "In this document we optimize model parameters and obtain a single, best refressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import datetime\n",
    "import traceback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import itertools\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from models.Utils import plot_confusion_matrix, plot_hbar_nameval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataset(y_val): \n",
    "    heading = 'Pitch index counts'\n",
    "    print(heading + '\\n' + '-'*len(heading))\n",
    "    for key, val in sorted(Counter(y_val).items()):\n",
    "        print('{}\\t: {}'.format(int(key), val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Traning Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('data_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(all_data.columns[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *i.Remove null events*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data['pitch_index'] !=0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch index counts\n",
      "------------------\n",
      "1\t: 19797\n",
      "2\t: 47201\n",
      "3\t: 18229\n",
      "4\t: 57806\n",
      "5\t: 169396\n",
      "6\t: 58463\n",
      "7\t: 21156\n",
      "8\t: 52785\n",
      "9\t: 24812\n"
     ]
    }
   ],
   "source": [
    "describe_dataset(all_data['pitch_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *ii.Scale data* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data.values[:, 0:-4]\n",
    "y = all_data.values[:, -3]\n",
    "\n",
    "# shuffle the data\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "# Scale the data to be between -1 and 1\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *iii.Split data* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Description\n",
    "Default classifier parameters. We will use these parameters as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters               : Current values\n",
      "-----------------------------------------\n",
      "max_depth                : None\n",
      "min_weight_fraction_leaf : 0.0\n",
      "n_jobs                   : 1\n",
      "n_estimators             : 128\n",
      "oob_score                : False\n",
      "max_features             : auto\n",
      "random_state             : None\n",
      "verbose                  : 0\n",
      "bootstrap                : True\n",
      "warm_start               : False\n",
      "min_samples_split        : 2\n",
      "max_leaf_nodes           : None\n",
      "min_impurity_decrease    : 0.0\n",
      "min_samples_leaf         : 1\n",
      "criterion                : mse\n",
      "min_impurity_split       : None\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(\n",
    "    n_estimators=128,\n",
    ")\n",
    "\n",
    "params = clf.get_params()\n",
    "max_key_len = max(len(key) for key in params.keys())\n",
    "max_val_len = max(len(str(val)) for val in params.values())\n",
    "header = '{:<{key_width}} : {:<{val_width}}'.format(\n",
    "    'Parameters',\n",
    "    'Current values',\n",
    "    key_width=max_key_len,\n",
    "    val_width=max_val_len\n",
    ")\n",
    "\n",
    "print(header)\n",
    "print('-'*len(header))\n",
    "for key, val in params.items():\n",
    "    print('{:{width}} : {}'.format(key, val, width=max_key_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "Search space. Every possible combination will be tested by GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "param_grid = [\n",
    "    {      'criterion': ['mse', 'mae'],\n",
    "           'max_features': ['sqrt', 'log2'],\n",
    "           'min_samples_split': [10, 25, 50, 75, 100]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of combinations: 40\n"
     ]
    }
   ],
   "source": [
    "prod = 1\n",
    "for key, val in param_grid[0].items():\n",
    "    prod *= len(val)\n",
    "    \n",
    "print('Total number of combinations: {}'.format(prod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=2, suffle=True)\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 40 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "# initial message accumulators\n",
    "train_result_msg = ''\n",
    "fmt = 'Training has ended in {} minutes and {} seconds'\n",
    "\n",
    "# we will measure time elapsed\n",
    "t_beg = datetime.datetime.now()\n",
    "try:\n",
    "    # train and save the grid search cross validator\n",
    "    grid_search_cv = grid_search_cv.fit(X_train, y_train)\n",
    "    with open('grid_search_cv.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search_cv, f)\n",
    "        \n",
    "    # success\n",
    "    fmt = 'SUCCESS! ' + fmt\n",
    "    fmt += '\\n\\n'\n",
    "\n",
    "    # build up success message with training results\n",
    "    result_dic = grid_search_cv.cv_results_\n",
    "    for header, content in sorted(result_dic.items()):\n",
    "        train_result_msg += '{}\\n{}\\n'.format(header, '-'*len(header))\n",
    "        train_result_msg += str(content)\n",
    "        train_result_msg += '\\n\\n\\n'\n",
    "except:\n",
    "    # send stack trace\n",
    "    fmt = 'FAILED! ' + fmt + '\\n\\n{}'.format(traceback.format_exc())\n",
    "finally:\n",
    "    # time elapsed\n",
    "    t = datetime.datetime.now() - t_beg\n",
    "    sec = t.seconds\n",
    "    minutes = sec//60\n",
    "    seconds = sec - 60*minutes\n",
    "    \n",
    "    # final message\n",
    "    msg = fmt.format(minutes, seconds) + train_result_msg\n",
    "\n",
    "# write the message to a file to be sent via email\n",
    "with open('grid_search_results.txt', 'w') as f:\n",
    "    f.write(msg + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
